{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.metrics import *\n",
    "from scipy.ndimage import interpolation\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mnist = fetch_openml(\"mnist_784\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = mnist.data\n",
    "targets = mnist.target\n",
    "labels = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "target_name = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moments(image):\n",
    "    c0,c1 = np.mgrid[:image.shape[0],:image.shape[1]] # A trick in numPy to create a mesh grid\n",
    "    totalImage = np.sum(image) #sum of pixels\n",
    "    m0 = np.sum(c0*image)/totalImage #mu_x\n",
    "    m1 = np.sum(c1*image)/totalImage #mu_y\n",
    "    m00 = np.sum((c0-m0)**2*image)/totalImage #var(x)\n",
    "    m11 = np.sum((c1-m1)**2*image)/totalImage #var(y)\n",
    "    m01 = np.sum((c0-m0)*(c1-m1)*image)/totalImage #covariance(x,y)\n",
    "    mu_vector = np.array([m0,m1]) # Notice that these are \\mu_x, \\mu_y respectively\n",
    "    covariance_matrix = np.array([[m00,m01],[m01,m11]]) # Do you see a similarity between the covariance matrix\n",
    "    return mu_vector, covariance_matrix\n",
    "\n",
    "def deskew(image):\n",
    "    c,v = moments(image)\n",
    "    alpha = v[0,1]/v[0,0]\n",
    "    affine = np.array([[1,0],[alpha,1]])\n",
    "    ocenter = np.array(image.shape)/2.0\n",
    "    offset = c-np.dot(affine,ocenter)\n",
    "    img = interpolation.affine_transform(image,affine,offset=offset)\n",
    "    return (img - img.min()) / (img.max() - img.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deskewed=[deskew(img) for img in trT[1]]\n",
    "# deskewedTr=np.array(deskewed)\n",
    "# print(deskewedTr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratify sampling\n",
    "def sampling(X, y, test_size=0.3, do_stratify=True):\n",
    "    if do_stratify:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=123, stratify=y)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=123, stratify=None)\n",
    "    \n",
    "    # scaler\n",
    "    sclaer = StandardScaler() # mean: 0, std: 1\n",
    "    # scaler = MinMaxScaler() # max: 1, min: 0\n",
    "    # scaler = RobustScaler() # median : 0, IQR : 1\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_target(target):\n",
    "    for i in range(10):\n",
    "        unique, counts = np.unique(target, return_counts=True)\n",
    "        \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM - linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [1000.0, 100.0, 10.0, 1.0, 0.1, 0.01, 0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gridsearchcv(X_train, y_train, C):\n",
    "    \"\"\"\n",
    "    SVC : C-Support Vector Classification.\n",
    "    GridSearchCV : Exhaustive search over specified parameter values for an estimator\n",
    "                   estimator : SVM Classifier\n",
    "                   parameters : linear kernel, C\n",
    "                   scoring : f1\n",
    "                   cross-validation : 10 times\n",
    "    \"\"\"\n",
    "    \n",
    "    parameters = {'kernel':['linear'], 'C':C}\n",
    "    \n",
    "    svc = SVC()\n",
    "    clf = GridSearchCV(estimator=svc, param_grid=parameters, scoring='f1', cv=10, n_jobs=-1)\n",
    "    # training\n",
    "    start_time = time.time()\n",
    "    %time clf.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "\n",
    "    best_param = clf.best_params_\n",
    "    best_score = clf.best_score_\n",
    "    \n",
    "    print(\"trainint time : \", end_time-start_time)\n",
    "    print(\"cv_validation_scores : \\n\", clf.cv_results_[\"cv_validation_scores\"]) # every result of cross-validation\n",
    "    print(\"mean_test_score : \\n\", clf.cv_results_[\"mean_test_score\"]) # mean of result of cross-validation\n",
    "    print(\"best\\n\", best_param \" : \\n\", best_score)\n",
    "    \n",
    "#     with open(\"./results/train.txt\", \"a\") as f:\n",
    "#         data = \"training time : \" + str(end_time-start_time) + \"\\n\"\n",
    "#         data += \"cv_validation_scores\\n\" + \"=\"*10 + \"n\" + str(clf.cv_results_[\"cv_validation_scores\"]) + \"\\n\"\n",
    "#         data += \"mean_test_score\\n\" + \"=\"*10 + \"n\" + str(clf.cv_results_[\"mean_test_score\"]) + \"\\n\"\n",
    "#         data += \"\\nbest_param : \" + str(best_param) + \"\\tbest_score : \" + str(best_score)\n",
    "#         f.write(data)\n",
    "    \n",
    "    return best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_run_time(X_train, y_train, C):\n",
    "    for c in C:\n",
    "        print(\"C is %f\" %c)\n",
    "\n",
    "        start_time = time.time()\n",
    "        %time clf = SVC(kernel=\"linear\", C=c).fix(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        print(\"running time : \", end_time - start_time)\n",
    "    \n",
    "#     with open(\"./results/diff_run_time.txt\", \"a\") as f:\n",
    "#         data = \"C is\" + str(C) + \"\\nrunning time : \" + str(end_time-start_time) + \"\\n\"\n",
    "#         f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_train, X_test, y_train, y_test, C, target_name):\n",
    "    clf = SVC(kernel=\"linear\", C=C).fit(X_train, y_train)\n",
    "    %time y_pred = clf.predict(X_test)\n",
    "    \n",
    "    cv_report = classification_report(y_test, y_pred, target_name=target_name)\n",
    "    print(\"cv_report\\n\", cv_report)\n",
    "    \n",
    "    res_SVM = []\n",
    "    res_SVM.append([accuracy_score(y_test, y_pred),\n",
    "              precision_score(y_test, y_pred, average=\"macro\"),\n",
    "              recall_score(y_test, y_pred, average=\"macro\"),\n",
    "              f1_score(y_test, y_pred, average=\"macro\")])\n",
    "    \n",
    "    # scores\n",
    "    res_pd = pd.DataFrame(res_SVM, columns = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"], index=[\"SVM\"])\n",
    "    print(res_pd)\n",
    "    \n",
    "    # confusion matrix\n",
    "    cmat = confusion_matrix(y_test, y_pred, target_name)\n",
    "    sns.set_palette(\"husl\")\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.heatmap(cmat, annot=True)\n",
    "    \n",
    "    # ROC curve\n",
    "    \n",
    "#     with open(\"./results/test_cv_report.txt\", \"a\") as f:\n",
    "#         data = \"classification report : \\n\" + str(cv_report)\n",
    "#         data += str(res_SVM[i] for i in range(4))\n",
    "#         f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sampling(images, targets, 0.3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of numbers after stratify sampling\n",
    "count_y_train = count_target(y_train)\n",
    "count_y_test = count_target(y_test)\n",
    "count_y = count_target(targets)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.bar(labels, count_y)\n",
    "plt.title(\"target\")\n",
    "plt.xticks(labels, labels)\n",
    "plt.yticks(count_y)\n",
    "plt.ylim(min(count_y)-100, max(count_y)+100)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.bar(labels, count_y_train)\n",
    "plt.title(\"y_train\")\n",
    "plt.xticks(labels, labels)\n",
    "plt.yticks(count_y_train)\n",
    "plt.ylim(min(count_y_train)-100, max(count_y_train)+100)\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.bar(labels, count_y_test)\n",
    "plt.title(\"y_test\")\n",
    "plt.xticks(labels, labels)\n",
    "plt.yticks(count_y_test)\n",
    "plt.ylim(min(count_y_test)-100, max(count_y_test)+100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_run_time(X_train, y_train, C=[1000.0, 1.0, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "param = run_gridsearchcv(X_train, y_train, sorted(C, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT UNCOMMENT!!\n",
    "# test(X_train, X_test, y_train, y_test, param, target_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
